### 高表现力语音合成

在交互、小说阅读等应用场景中，对合成语音的表现力要求较高，而表现力由内容、说话人音色、韵律、情感和风格等多个因素决定，因此高表现力语音合成实际涵盖了内容、音色、韵律、情感和风格的建模、分离和控制。

语音中包含的信息可以分为如下四类：

1.  字符或音素，也就是语音的内容。可以通过预训练词嵌入增强合成语音的表现力和质量，或者加入一些额外的信息，比如升降调信息、采用fulllab能够增强模型表现力和稳定性。fulllab及传统语音合成采用的文本、声学特征参见：[jsut
    lab](https://github.com/r9y9/jsut-lab)、[HTS Data
    README](https://github.com/feelins/HTS-Project/blob/master/data/README)。

2.  说话人或音色。多说话人语音合成模型可以通过说话人嵌入向量或单独的说话人编码器（speaker
    encoder）对音色特征进行建模。

3.  韵律、风格和情感。这些特征表示"如何说出文本"，表征语音中的语调、重音和说话节奏，韵律、风格和情感是高表现力语音合成的建模重点。

4.  录音设备和环境噪音。这些倒是与语音内容、韵律无关，但会显著影响语音质量，因此可以尝试对语音中的噪音等进行控制和分离。对训练语料本身可以提前进行去噪处理，在模型中可以标识带噪语料，以便在合成语音中去除噪音部分。

利用模型建模这些信息的方法很多，有语种、说话人、风格嵌入向量以及音高、时长、能量编码器等显式建模方法，也有reference
encoder、VAE、GAN/Flow/Diffusion、文本预训练等隐式建模方法。